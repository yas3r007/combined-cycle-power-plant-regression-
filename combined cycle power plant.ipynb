{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20a60864-0dfd-447f-bfbf-77a0ceda042e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24b6559c-f83e-4169-8d4e-859bcf71adc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f42494ef-1081-44d4-922e-f15e66b1ba8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>V</th>\n",
       "      <th>AP</th>\n",
       "      <th>RH</th>\n",
       "      <th>PE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.96</td>\n",
       "      <td>41.76</td>\n",
       "      <td>1024.07</td>\n",
       "      <td>73.17</td>\n",
       "      <td>463.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.18</td>\n",
       "      <td>62.96</td>\n",
       "      <td>1020.04</td>\n",
       "      <td>59.08</td>\n",
       "      <td>444.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.11</td>\n",
       "      <td>39.40</td>\n",
       "      <td>1012.16</td>\n",
       "      <td>92.14</td>\n",
       "      <td>488.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.86</td>\n",
       "      <td>57.32</td>\n",
       "      <td>1010.24</td>\n",
       "      <td>76.64</td>\n",
       "      <td>446.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.82</td>\n",
       "      <td>37.50</td>\n",
       "      <td>1009.23</td>\n",
       "      <td>96.62</td>\n",
       "      <td>473.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AT      V       AP     RH      PE\n",
       "0  14.96  41.76  1024.07  73.17  463.26\n",
       "1  25.18  62.96  1020.04  59.08  444.37\n",
       "2   5.11  39.40  1012.16  92.14  488.56\n",
       "3  20.86  57.32  1010.24  76.64  446.48\n",
       "4  10.82  37.50  1009.23  96.62  473.90"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_excel(\"Folds5x2_pp.xlsx\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599f21da-0ed8-4216-b83a-d7cd90dcf597",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AT=AMBIENT TEMPERATURE,AP=ATMOSPHERIC PRESSURE,RH=RELATIVE HUMIDITY,V=EXHAUST VACCUM,PE=NET HOURLY ELECTRICAL ENERGY OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "594276e1-a5f7-44df-bbca-2b6ae3e0f0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9568 entries, 0 to 9567\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   AT      9568 non-null   float64\n",
      " 1   V       9568 non-null   float64\n",
      " 2   AP      9568 non-null   float64\n",
      " 3   RH      9568 non-null   float64\n",
      " 4   PE      9568 non-null   float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 373.9 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8ac06bc-b1c3-41c0-8923-193c17a6ec3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AT', 'V', 'AP', 'RH', 'PE'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5065830d-4de4-4074-a940-8b35245979f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "continous=['AT', 'V', 'AP', 'RH', 'PE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78dd867b-018e-42f1-b4eb-37b291dbd653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.96, 25.18,  5.11, ..., 30.  ,  5.01,  9.71])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"AT\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb9e57c8-5b3d-490c-8665-df85a5e135bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([41.76, 62.96, 39.4 , 57.32, 37.5 , 59.44, 43.96, 44.71, 45.  ,\n",
       "       43.56, 43.72, 46.93, 73.5 , 58.59, 69.34, 43.79, 41.74, 52.75,\n",
       "       38.47, 42.42, 40.07, 42.28, 63.9 , 48.6 , 70.72, 39.31, 39.96,\n",
       "       35.79, 65.18, 63.94, 58.41, 66.85, 74.16, 44.03, 63.73, 47.45,\n",
       "       39.35, 51.3 , 44.85, 41.54, 42.86, 40.64, 37.87, 43.43, 40.11,\n",
       "       38.62, 78.92, 42.18, 39.39, 59.43, 64.44, 39.33, 61.08, 58.84,\n",
       "       52.3 , 65.71, 40.1 , 45.87, 58.79, 65.34, 40.69, 34.03, 74.34,\n",
       "       68.3 , 41.01, 74.67, 61.02, 39.85, 69.75, 67.25, 76.86, 69.45,\n",
       "       43.02, 45.08, 73.68, 39.3 , 58.96, 68.94, 51.43, 64.05, 60.95,\n",
       "       41.66, 52.72, 67.32, 40.72, 66.48, 63.77, 59.21, 43.69, 41.38,\n",
       "       71.94, 62.66, 49.69, 44.2 , 65.59, 40.89, 61.87, 58.33, 39.72,\n",
       "       43.48, 46.21, 59.39, 41.1 , 66.93, 42.85, 50.88, 54.2 , 68.67,\n",
       "       73.18, 73.88, 60.84, 45.09, 57.76, 43.77, 63.76, 47.43, 62.91,\n",
       "       39.04, 44.78, 69.05, 59.8 , 65.06, 68.14, 42.32, 40.77, 62.52,\n",
       "       48.41, 39.9 , 49.39, 46.97, 40.05, 49.21, 61.45, 66.51, 66.86,\n",
       "       49.78, 56.89, 43.65, 43.41, 41.58, 52.84, 42.74, 44.34, 71.98,\n",
       "       37.73, 44.21, 71.58, 50.16, 59.04, 71.14, 52.05, 59.54, 69.84,\n",
       "       71.37, 74.99, 63.07, 57.25, 70.98, 36.24, 39.63, 54.42, 56.85,\n",
       "       42.48, 44.89, 58.2 , 57.85, 63.86, 39.52, 64.63, 63.56, 79.74,\n",
       "       42.03, 69.51, 41.49, 41.62, 43.13, 59.87, 44.9 , 44.84, 75.6 ,\n",
       "       40.96, 44.06, 69.13, 39.22, 44.47, 40.12, 63.21, 58.46, 39.  ,\n",
       "       36.08, 60.07, 39.48, 71.64, 68.08, 39.54, 67.79, 41.26, 72.58,\n",
       "       40.23, 58.95, 70.79, 70.47, 58.49, 57.19, 42.44, 59.14, 40.22,\n",
       "       39.82, 40.71, 72.39, 77.54, 71.97, 40.78, 62.26, 38.91, 58.82,\n",
       "       56.53, 54.3 , 44.58, 39.1 , 70.83, 64.79, 63.47, 41.46, 58.16,\n",
       "       71.25, 41.5 , 44.6 , 65.27, 41.82, 49.82, 66.56, 39.58, 42.49,\n",
       "       58.86, 73.77, 73.91, 60.29, 69.89, 72.29, 60.27, 59.15, 67.45,\n",
       "       41.17, 40.73, 69.14, 45.51, 50.78, 73.67, 73.21, 39.61, 71.32,\n",
       "       41.79, 71.77, 66.75, 40.55, 61.27, 40.  , 69.68, 25.36, 49.3 ,\n",
       "       40.56, 39.16, 40.66, 39.59, 67.71, 59.92, 41.4 , 41.2 , 44.68,\n",
       "       65.46, 41.93, 36.99, 57.17, 57.5 , 45.78, 35.57, 38.08, 77.95,\n",
       "       46.63, 70.02, 69.88, 40.67, 37.14, 49.83, 41.04, 48.06, 56.03,\n",
       "       72.99, 69.4 , 67.17, 44.57, 72.24, 77.17, 41.39, 50.23, 49.5 ,\n",
       "       64.69, 43.14, 48.78, 37.85, 63.09, 68.27, 47.93, 43.67, 34.69,\n",
       "       75.33, 69.71, 70.8 , 73.56, 65.74, 43.22, 68.24, 66.54, 44.45,\n",
       "       42.02, 50.66, 69.94, 39.64, 39.69, 70.04, 43.34, 72.86, 69.98,\n",
       "       40.81, 40.02, 56.65, 41.48, 40.83, 46.18, 74.78, 53.82, 39.42,\n",
       "       41.06, 61.25, 41.85, 36.25, 44.63, 48.79, 41.78, 49.16, 68.28,\n",
       "       40.79, 45.01, 66.49, 43.71, 50.59, 66.05, 41.31, 44.92, 70.32,\n",
       "       41.92, 66.44, 60.32, 61.41, 70.4 , 68.51, 64.45, 63.31, 60.23,\n",
       "       52.36, 48.92, 40.46, 40.27, 43.52, 41.16, 38.25, 40.75, 39.28,\n",
       "       51.19, 53.16, 48.04, 67.07, 48.98, 58.66, 43.99, 36.71, 72.43,\n",
       "       48.14, 40.92, 76.2 , 75.23, 74.22, 38.44, 36.18, 58.62, 40.43,\n",
       "       54.9 , 41.44, 49.15, 62.08, 49.25, 70.94, 68.31, 40.8 , 44.88,\n",
       "       74.33, 41.14, 65.48, 69.59, 52.08, 62.39, 71.29, 41.23, 50.32,\n",
       "       58.9 , 50.05, 43.5 , 75.08, 37.83, 49.02, 38.73, 63.13, 41.03,\n",
       "       42.34, 39.66, 62.04, 36.66, 47.83, 55.5 , 47.01, 50.9 , 71.06,\n",
       "       73.42, 39.81, 68.84, 38.06, 40.62, 73.17, 64.15, 41.67, 37.92,\n",
       "       46.48, 42.99, 38.78, 73.03, 67.9 , 38.52, 38.28, 42.77, 61.5 ,\n",
       "       41.35, 69.82, 52.9 , 74.9 , 40.35, 67.69, 37.64, 64.27, 60.08,\n",
       "       63.87, 77.24, 65.12, 71.22, 68.61, 40.03, 38.68, 39.18, 69.48,\n",
       "       56.9 , 45.17, 38.56, 49.64, 68.12, 38.38, 67.83, 39.99, 66.25,\n",
       "       44.99, 43.7 , 60.93, 65.61, 35.77, 77.3 , 64.33, 71.8 , 40.6 ,\n",
       "       38.5 , 44.05, 59.27, 47.03, 37.49, 56.51, 42.67, 42.23, 39.37,\n",
       "       68.63, 59.57, 35.47, 60.37, 69.23, 73.06, 38.18, 51.86, 36.3 ,\n",
       "       61.86, 60.77, 37.8 , 62.1 , 39.53, 65.38, 42.04, 35.76, 41.55,\n",
       "       53.29, 71.85, 65.94, 69.04, 62.4 , 42.8 , 72.51, 74.93, 64.84,\n",
       "       73.9 , 63.91, 45.38, 60.1 , 56.57, 73.4 , 42.07, 54.5 , 37.36,\n",
       "       74.87, 70.17, 40.2 , 50.12, 63.57, 70.36, 58.05, 63.78, 51.61,\n",
       "       70.09, 35.71, 41.7 , 71.73, 43.21, 51.95, 64.96, 61.47, 41.22,\n",
       "       80.18, 44.  , 52.09, 38.01, 25.88, 67.51, 45.61, 40.24, 44.77,\n",
       "       57.82, 62.7 , 37.2 , 45.64, 42.24, 58.12, 71.43, 44.66, 56.86,\n",
       "       72.25, 65.51, 43.8 , 46.33, 62.44, 59.07, 39.13, 38.92, 45.76,\n",
       "       66.91, 79.05, 46.9 , 65.75, 48.7 , 46.36, 76.09, 36.43, 60.96,\n",
       "       35.4 , 61.9 , 46.  , 67.22, 58.71, 58.98, 55.97, 62.34, 73.11,\n",
       "       47.24, 57.69, 78.05, 73.46, 78.87, 35.19, 60.75, 64.34, 59.74,\n",
       "       59.22, 58.18, 38.58, 57.35, 62.6 , 41.96, 53.53, 81.56, 80.25,\n",
       "       44.37, 58.69, 56.24, 37.7 , 57.43, 44.3 , 38.16, 78.11, 57.55,\n",
       "       38.53, 53.3 , 39.08, 37.9 , 67.48, 55.68, 66.17, 35.85, 61.85,\n",
       "       41.43, 37.86, 55.28, 36.54, 64.09, 37.91, 40.33, 67.98, 76.16,\n",
       "       54.89, 50.39, 68.37, 60.06])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"V\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55b15823-fb25-4fa7-a027-69a25a9ab160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1024.07, 1020.04, 1012.16, ..., 1027.12, 1024.16, 1023.67])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"AP\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23a77d52-c4e4-4f08-b75f-6c2d70d22e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([73.17, 59.08, 92.14, ..., 94.03, 63.83, 36.48])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"RH\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "522243e1-ce77-4be7-aef5-b962833fd4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([463.26, 444.37, 488.56, ..., 484.33, 443.21, 469.62])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"PE\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adc88f27-4423-4ce8-b397-a0ede7d993e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AT\n",
       "25.21    14\n",
       "13.78    12\n",
       "24.43    11\n",
       "23.56    10\n",
       "11.02    10\n",
       "         ..\n",
       "9.89      1\n",
       "7.34      1\n",
       "12.92     1\n",
       "27.72     1\n",
       "9.71      1\n",
       "Name: count, Length: 2773, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"AT\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81a96df1-17dc-4dbb-b8e4-40a2660cf121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AT\n",
       "25.21    14\n",
       "13.78    12\n",
       "24.43    11\n",
       "23.56    10\n",
       "11.02    10\n",
       "         ..\n",
       "9.89      1\n",
       "7.34      1\n",
       "12.92     1\n",
       "27.72     1\n",
       "9.71      1\n",
       "Name: count, Length: 2773, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"AT\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87bcfa48-9ca3-4f2b-9a68-f4207690369d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AT\n",
       "25.21    14\n",
       "13.78    12\n",
       "24.43    11\n",
       "23.56    10\n",
       "11.02    10\n",
       "         ..\n",
       "9.89      1\n",
       "7.34      1\n",
       "12.92     1\n",
       "27.72     1\n",
       "9.71      1\n",
       "Name: count, Length: 2773, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"AT\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6db5acc-aecb-43a4-8b1d-17852861ca75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AT\n",
       "25.21    14\n",
       "13.78    12\n",
       "24.43    11\n",
       "23.56    10\n",
       "11.02    10\n",
       "         ..\n",
       "9.89      1\n",
       "7.34      1\n",
       "12.92     1\n",
       "27.72     1\n",
       "9.71      1\n",
       "Name: count, Length: 2773, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"AT\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05d4e834-e6d8-45bd-83c9-4c5a653512c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AT\n",
       "25.21    14\n",
       "13.78    12\n",
       "24.43    11\n",
       "23.56    10\n",
       "11.02    10\n",
       "         ..\n",
       "9.89      1\n",
       "7.34      1\n",
       "12.92     1\n",
       "27.72     1\n",
       "9.71      1\n",
       "Name: count, Length: 2773, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"AT\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae1d7b7c-5654-4aff-8964-888ad321d471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boxplot(data,ft):\n",
    "    data.boxplot(column=[ft])\n",
    "    plt.grid(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3278a297-4ebf-4b33-8d70-7fd5a30b82bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers(data,ft):\n",
    "    Q1=data[ft].quantile(0.25)\n",
    "    Q3=data[ft].quantile(0.75)\n",
    "    IQR=Q3-Q1\n",
    "    lower_bound=Q1-1.5*IQR\n",
    "    upper_bound=Q3+1.5*IQR\n",
    "\n",
    "    ls=data.index[ (data[ft] < lower_bound) | (data[ft]> upper_bound) ]\n",
    "\n",
    "    return ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6029bd26-86b8-4bd2-bd34-bea922be03f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[238,\n",
       " 319,\n",
       " 368,\n",
       " 536,\n",
       " 571,\n",
       " 631,\n",
       " 669,\n",
       " 715,\n",
       " 753,\n",
       " 810,\n",
       " 847,\n",
       " 983,\n",
       " 1091,\n",
       " 1250,\n",
       " 1290,\n",
       " 1388,\n",
       " 1583,\n",
       " 1660,\n",
       " 1808,\n",
       " 2003,\n",
       " 2060,\n",
       " 2298,\n",
       " 2372,\n",
       " 2395,\n",
       " 2447,\n",
       " 2481,\n",
       " 2579,\n",
       " 2761,\n",
       " 2972,\n",
       " 2977,\n",
       " 2989,\n",
       " 3015,\n",
       " 3021,\n",
       " 3066,\n",
       " 3213,\n",
       " 3412,\n",
       " 3443,\n",
       " 3483,\n",
       " 3492,\n",
       " 3766,\n",
       " 3796,\n",
       " 3955,\n",
       " 4067,\n",
       " 4125,\n",
       " 4202,\n",
       " 4327,\n",
       " 4697,\n",
       " 4793,\n",
       " 4928,\n",
       " 5006,\n",
       " 5067,\n",
       " 5431,\n",
       " 5529,\n",
       " 5690,\n",
       " 5706,\n",
       " 5805,\n",
       " 5840,\n",
       " 5863,\n",
       " 5928,\n",
       " 5956,\n",
       " 6006,\n",
       " 6346,\n",
       " 6581,\n",
       " 6708,\n",
       " 6789,\n",
       " 6829,\n",
       " 6925,\n",
       " 7077,\n",
       " 7186,\n",
       " 7320,\n",
       " 7485,\n",
       " 7623,\n",
       " 7807,\n",
       " 7892,\n",
       " 8098,\n",
       " 8104,\n",
       " 8133,\n",
       " 8270,\n",
       " 8379,\n",
       " 8411,\n",
       " 8462,\n",
       " 8568,\n",
       " 9060,\n",
       " 9068,\n",
       " 9159,\n",
       " 9267,\n",
       " 9342,\n",
       " 9366,\n",
       " 789,\n",
       " 2262,\n",
       " 3603,\n",
       " 4367,\n",
       " 6472,\n",
       " 7983,\n",
       " 8061,\n",
       " 8737,\n",
       " 8751,\n",
       " 9015,\n",
       " 9074,\n",
       " 9075]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_list=[]\n",
    "for feature in ['AT', 'V', 'AP', 'RH','PE']:\n",
    "    index_list.extend(outliers(data,feature))\n",
    "index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ba95305-2149-4507-a389-740e09e7be7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def remove(data,ls):\n",
    "#  ls=sorted(set(ls))\n",
    "#   data=data.drop(ls)\n",
    "#    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "993df55b-ac5c-45f0-8a92-30bc93393a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_cleaned=remove(data,index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18d58db3-cac1-4614-ab1f-a16b0672e348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AT   -0.136393\n",
       "V     0.198521\n",
       "AP    0.265445\n",
       "RH   -0.431839\n",
       "PE    0.306509\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0377d451-49a2-41da-9564-7b78a5bbbbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop(\"PE\",axis=1)\n",
    "y=data[\"PE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a3a32d8-0859-4a29-b1c1-b2465c8eaad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 458.3558797966692\n",
      "coefficients: [-1.97253609 -0.23689539  0.05852478 -0.15902722]\n",
      "Train R2: 0.9281184327195898\n",
      "Test R2: 0.9309231890731563\n",
      "cross validation score: 0.9285378066739305\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=9)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model1=LinearRegression()\n",
    "model1.fit(X_train,y_train)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"Intercept:\",model1.intercept_)\n",
    "print(\"coefficients:\",model1.coef_)\n",
    "\n",
    "train_predictions=model1.predict(X_train)\n",
    "test_predictions=model1.predict(X_test)\n",
    "\n",
    "print(\"Train R2:\",model1.score(X_train,y_train))\n",
    "print(\"Test R2:\",model1.score(X_test,y_test))\n",
    "print(\"cross validation score:\",cross_val_score(model1,X,y,cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea99ed2a-c488-472f-98b2-fa4fbb29052e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variance Inflation Factor (VIF):\n",
      "   feature        VIF\n",
      "0      AT  39.157705\n",
      "1       V  74.969127\n",
      "2      AP  66.618618\n",
      "3      RH  40.704756\n"
     ]
    }
   ],
   "source": [
    "vif_data = pd.DataFrame()\n",
    "vif_data['feature'] = X.columns\n",
    "vif_data['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "print(\"\\nVariance Inflation Factor (VIF):\\n\", vif_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52d89758-e5df-4c30-8131-387a1b12daa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.929</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.929</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>3.114e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 18 Jul 2024</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:07:09</td>     <th>  Log-Likelihood:    </th> <td> -28088.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  9568</td>      <th>  AIC:               </th> <td>5.619e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  9563</td>      <th>  BIC:               </th> <td>5.622e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  454.6093</td> <td>    9.749</td> <td>   46.634</td> <td> 0.000</td> <td>  435.500</td> <td>  473.718</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X[0]</th>      <td>   -1.9775</td> <td>    0.015</td> <td> -129.342</td> <td> 0.000</td> <td>   -2.007</td> <td>   -1.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X[1]</th>      <td>   -0.2339</td> <td>    0.007</td> <td>  -32.122</td> <td> 0.000</td> <td>   -0.248</td> <td>   -0.220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X[2]</th>      <td>    0.0621</td> <td>    0.009</td> <td>    6.564</td> <td> 0.000</td> <td>    0.044</td> <td>    0.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X[3]</th>      <td>   -0.1581</td> <td>    0.004</td> <td>  -37.918</td> <td> 0.000</td> <td>   -0.166</td> <td>   -0.150</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>892.002</td> <th>  Durbin-Watson:     </th> <td>   2.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>4086.777</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.352</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.123</td>  <th>  Cond. No.          </th> <td>2.13e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.13e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.929   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.929   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } & 3.114e+04   \\\\\n",
       "\\textbf{Date:}             & Thu, 18 Jul 2024 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}             &     16:07:09     & \\textbf{  Log-Likelihood:    } &   -28088.   \\\\\n",
       "\\textbf{No. Observations:} &        9568      & \\textbf{  AIC:               } & 5.619e+04   \\\\\n",
       "\\textbf{Df Residuals:}     &        9563      & \\textbf{  BIC:               } & 5.622e+04   \\\\\n",
       "\\textbf{Df Model:}         &           4      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &     454.6093  &        9.749     &    46.634  &         0.000        &      435.500    &      473.718     \\\\\n",
       "\\textbf{X[0]}      &      -1.9775  &        0.015     &  -129.342  &         0.000        &       -2.007    &       -1.948     \\\\\n",
       "\\textbf{X[1]}      &      -0.2339  &        0.007     &   -32.122  &         0.000        &       -0.248    &       -0.220     \\\\\n",
       "\\textbf{X[2]}      &       0.0621  &        0.009     &     6.564  &         0.000        &        0.044    &        0.081     \\\\\n",
       "\\textbf{X[3]}      &      -0.1581  &        0.004     &   -37.918  &         0.000        &       -0.166    &       -0.150     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 892.002 & \\textbf{  Durbin-Watson:     } &    2.033  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 4086.777  \\\\\n",
       "\\textbf{Skew:}          &  -0.352 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &   6.123 & \\textbf{  Cond. No.          } & 2.13e+05  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 2.13e+05. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.929\n",
       "Model:                            OLS   Adj. R-squared:                  0.929\n",
       "Method:                 Least Squares   F-statistic:                 3.114e+04\n",
       "Date:                Thu, 18 Jul 2024   Prob (F-statistic):               0.00\n",
       "Time:                        16:07:09   Log-Likelihood:                -28088.\n",
       "No. Observations:                9568   AIC:                         5.619e+04\n",
       "Df Residuals:                    9563   BIC:                         5.622e+04\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    454.6093      9.749     46.634      0.000     435.500     473.718\n",
       "X[0]          -1.9775      0.015   -129.342      0.000      -2.007      -1.948\n",
       "X[1]          -0.2339      0.007    -32.122      0.000      -0.248      -0.220\n",
       "X[2]           0.0621      0.009      6.564      0.000       0.044       0.081\n",
       "X[3]          -0.1581      0.004    -37.918      0.000      -0.166      -0.150\n",
       "==============================================================================\n",
       "Omnibus:                      892.002   Durbin-Watson:                   2.033\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4086.777\n",
       "Skew:                          -0.352   Prob(JB):                         0.00\n",
       "Kurtosis:                       6.123   Cond. No.                     2.13e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.13e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "model2=smf.ols(\"y~X\",data=data).fit()\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "063573de-d1c0-4112-aad8-e74af9dae839",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "babfdb7e-2eb7-4e64-87c1-0b6776064bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 4.25654379557425\n",
      "Train R2: 0.9378161472059803\n",
      "Cross Validation Score: 0.9374750666020747\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "polynomial_converter=PolynomialFeatures(degree=2)\n",
    "X_train_poly=pd.DataFrame(polynomial_converter.fit_transform(X_train))\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model=LinearRegression()\n",
    "model.fit(X_train_poly,y_train)\n",
    "\n",
    "ypred_train=model.predict(X_train_poly)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "print(\"Train RMSE:\",np.sqrt(mean_squared_error(y_train,ypred_train)))\n",
    "print(\"Train R2:\",r2_score(y_train,ypred_train))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"Cross Validation Score:\",cross_val_score(model,X_train_poly,y_train,cv=5).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b99cef6f-892d-4282-a20a-35918d2d575b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 4.254326301460243\n",
      "Test R2: 0.9377179628847947\n"
     ]
    }
   ],
   "source": [
    "X_test_poly=pd.DataFrame(polynomial_converter.transform(X_test))\n",
    "\n",
    "ypred_test=model.predict(X_test_poly)\n",
    "\n",
    "print(\"Test RMSE:\",np.sqrt(mean_squared_error(y_test,ypred_test)))\n",
    "print(\"Test R2:\",r2_score(y_test,ypred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ebd703e9-ddbc-463f-b94a-065b547569cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_r2=[]\n",
    "test_r2=[]\n",
    "\n",
    "for i in range(1,10):\n",
    "    polynomial_converter=PolynomialFeatures(degree=i)\n",
    "    X_train_poly=pd.DataFrame(polynomial_converter.fit_transform(X_train))\n",
    "\n",
    "    model=LinearRegression()\n",
    "    model.fit(X_train_poly,y_train)\n",
    "\n",
    "    train_pred=model.predict(X_train_poly)\n",
    "    train_r2.append(model.score(X_train_poly,y_train))\n",
    "\n",
    "    X_test_poly=pd.DataFrame(polynomial_converter.transform(X_test))\n",
    "\n",
    "    test_pred=model.predict(X_test_poly)\n",
    "    test_r2.append(model.score(X_test_poly,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "526a6adb-52c4-40a5-b791-0521e5df5601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9287417335236683,\n",
       " 0.9378161472059803,\n",
       " 0.940729195363161,\n",
       " 0.9426193654868534,\n",
       " 0.9446788460661021,\n",
       " 0.9460333671392918,\n",
       " 0.9470865370667045,\n",
       " 0.9464520590666022,\n",
       " 0.946797910530958]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c985a572-3ac0-4e76-b99c-d73d7aa56973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9284252072118927,\n",
       " 0.9377179628847947,\n",
       " 0.9411051207322805,\n",
       " 0.9424874182023198,\n",
       " 0.9438469086702983,\n",
       " 0.945829487368187,\n",
       " 0.9442847336843304,\n",
       " 0.9424291890514008,\n",
       " 0.9452069994580989]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cdb78dec-908b-4af0-8c1a-fe72c6c3cbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train R2: 0.9460333671392918\n",
      "Cross validation score: 0.9426078450507012\n",
      "test R2: 0.945829487368187\n"
     ]
    }
   ],
   "source": [
    "final_poly_converter=PolynomialFeatures(degree=6)\n",
    "X_train_poly=pd.DataFrame(final_poly_converter.fit_transform(X_train))\n",
    "\n",
    "final_model=LinearRegression()\n",
    "final_model.fit(X_train_poly,y_train)\n",
    "\n",
    "train_pred=final_model.predict(X_train_poly)\n",
    "print(\"train R2:\",final_model.score(X_train_poly,y_train))\n",
    "print(\"Cross validation score:\",cross_val_score(model,X_train_poly,y_train,cv=5).mean())\n",
    "\n",
    "X_test_poly=pd.DataFrame(final_poly_converter.transform(X_test))\n",
    "test_pred=final_model.predict(X_test_poly)\n",
    "print(\"test R2:\",final_model.score(X_test_poly,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b262a27-bbd4-4747-88df-37623fd50781",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36395b94-5250-42f3-baf8-4e6aa09ba222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "estimator=Lasso()\n",
    "param_grid={\"alpha\":list(range(1,100))}\n",
    "\n",
    "model_hp=GridSearchCV(estimator,param_grid,cv=5,scoring='r2')\n",
    "\n",
    "model_hp.fit(X_train,y_train)\n",
    "model_hp.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "204a185e-3ee3-41cc-9505-c7c4012df3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 469.99020855487066\n",
      "coefficients: [-1.91692691 -0.25504403  0.045803   -0.14336738]\n",
      "train r2: 0.9278927920705954\n",
      "Cv score: 0.9277105859223717\n",
      "test r2: 0.930545862866579\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso_best=Lasso(alpha=1)\n",
    "lasso_best.fit(X_train,y_train)\n",
    "\n",
    "print(\"Intercept:\",lasso_best.intercept_)\n",
    "print(\"coefficients:\",lasso_best.coef_)\n",
    "\n",
    "ypred_train=lasso_best.predict(X_train)\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"train r2:\",r2_score(y_train,ypred_train))\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"Cv score:\",cross_val_score(lasso_best,X_train,y_train,cv=5).mean())\n",
    "\n",
    "ypred_test=lasso_best.predict(X_test)\n",
    "print(\"test r2:\",r2_score(y_test,ypred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c7d2aa7a-e628-4ce6-9abe-98bc0b55cef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 86}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "estimator=Ridge()\n",
    "\n",
    "param_grid={\"alpha\":list(range(1,100))}\n",
    "\n",
    "model_hp=GridSearchCV(estimator,param_grid,cv=5,scoring='r2')\n",
    "\n",
    "model_hp.fit(X_train,y_train)\n",
    "model_hp.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cc285774-9237-4c34-aee2-c346dc2b84fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept: 452.233241377168\n",
      "coefficients: [-1.97083479 -0.23736736  0.06445296 -0.15768559]\n",
      "train r2: 0.9277252321177676\n",
      "cv Score: 0.9274552056083067\n",
      "test r2: 0.932528360586564\n"
     ]
    }
   ],
   "source": [
    "ridge_best=Ridge(alpha=86)\n",
    "ridge_best.fit(X_train,y_train)\n",
    "\n",
    "print(\"intercept:\",ridge_best.intercept_)\n",
    "print(\"coefficients:\",ridge_best.coef_)\n",
    "\n",
    "ypred_train=ridge_best.predict(X_train)\n",
    "print(\"train r2:\",r2_score(y_train,ypred_train))\n",
    "print(\"cv Score:\",cross_val_score(ridge_best,X_train,y_train,cv=5).mean())\n",
    "\n",
    "ypred_test=ridge_best.predict(X_test)\n",
    "print(\"test r2:\",r2_score(y_test,ypred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2c8b2f81-6176-49b8-9209-73adf69154aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train R2: 0.9276050603307082\n",
      "test R2: 0.9301809469006899\n",
      "cross Validation Score: 0.9280334249499027\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=9)\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "enr_base=ElasticNet()\n",
    "enr_base.fit(X_train,y_train)\n",
    "\n",
    "train_predictions=enr_base.predict(X_train)\n",
    "test_predictions=enr_base.predict(X_test)\n",
    "\n",
    "print(\"train R2:\",enr_base.score(X_train,y_train))\n",
    "print(\"test R2:\",enr_base.score(X_test,y_test))\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"cross Validation Score:\",cross_val_score(enr_base,X,y,cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "feaa9fd9-c285-4ffb-8a07-1fe4de2e527b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.1, 'l1_ratio': 1}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "estimator=ElasticNet()\n",
    "\n",
    "param_grid={\"alpha\":[0.1,0.2,1,2,3,5,10],\"l1_ratio\":[0.1,0.5,0.75,0.9,0.95,1]}\n",
    "\n",
    "model_hp=GridSearchCV(estimator,param_grid,cv=5,scoring='neg_mean_squared_error')\n",
    "model_hp.fit(X_train,y_train)\n",
    "model_hp.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ea1835e8-46de-4e99-b435-75f4244513e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept: 459.6933971005806\n",
      "coefficients [-1.96757445 -0.23849951  0.05708851 -0.15756332]\n",
      "Train R2: 0.928116387007527\n",
      "test R2: 0.9309066744902176\n",
      "cross validation score: 0.9285358237152195\n"
     ]
    }
   ],
   "source": [
    "enr_best=ElasticNet(alpha=0.1,l1_ratio=1)\n",
    "enr_best.fit(X_train,y_train)\n",
    "\n",
    "print(\"intercept:\",enr_best.intercept_)\n",
    "print(\"coefficients\",enr_best.coef_)\n",
    "\n",
    "train_predictions=enr_best.predict(X_train)\n",
    "test_predictions=enr_best.predict(X_test)\n",
    "\n",
    "print(\"Train R2:\",enr_best.score(X_train,y_train))\n",
    "print(\"test R2:\",enr_best.score(X_test,y_test))\n",
    "print(\"cross validation score:\",cross_val_score(enr_best,X,y,cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4e21808a-b021-4ea6-9c03-46d372660056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7c8218d9-ced9-4e43-91bb-6812b8e58f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a1e6b91-4af4-4d2c-bd8a-bbc8e8d95c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a36c88a5-f324-427a-bd30-025874e18355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_model_regressor():\n",
    "    \n",
    "    model=Sequential()\n",
    "\n",
    "    model.add(Dense(input_dim=4,units=6,activation=\"relu\",kernel_initializer=\"uniform\"))\n",
    "\n",
    "    model.add(Dense(units=6,activation=\"relu\",kernel_initializer=\"uniform\"))\n",
    "\n",
    "    model.add(Dense(units=1,activation=\"relu\",kernel_intitializer=\"uniform\"))\n",
    "\n",
    "    model.compile(optimizer=\"adam\",loss=\"mean_squared_error\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ac2fe6bf-dc86-41d1-b724-94b308fae9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_model_regressor():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(input_dim=4,units=6,activation=\"relu\",kernel_initializer=\"uniform\"))\n",
    "    model.add(Dense(units=6,activation=\"relu\",kernel_initializer=\"uniform\"))\n",
    "    model.add(Dense(units=1,activation=\"relu\",kernel_initializer=\"uniform\"))\n",
    "    model.compile(optimizer=\"adam\",loss=\"mean_squared_error\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7d9d7367-21eb-4519-8484-a02137ebf778",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann=ann_model_regressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e0250691-1368-499e-ba64-1b7dbb2d676e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 206509.7344\n",
      "Epoch 2/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 200616.8906\n",
      "Epoch 3/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 174677.8125\n",
      "Epoch 4/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 126006.6641\n",
      "Epoch 5/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74858.8203\n",
      "Epoch 6/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 43024.8398\n",
      "Epoch 7/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 27009.7559\n",
      "Epoch 8/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 19032.5293\n",
      "Epoch 9/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 14241.5537\n",
      "Epoch 10/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11120.1201\n",
      "Epoch 11/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8182.8179\n",
      "Epoch 12/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5719.7178\n",
      "Epoch 13/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4007.4802\n",
      "Epoch 14/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2887.0383\n",
      "Epoch 15/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2272.9143\n",
      "Epoch 16/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1769.0994\n",
      "Epoch 17/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1445.0989\n",
      "Epoch 18/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1110.4729\n",
      "Epoch 19/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 877.3414\n",
      "Epoch 20/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 676.3580\n",
      "Epoch 21/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 454.4178\n",
      "Epoch 22/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 333.0967\n",
      "Epoch 23/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 212.0138\n",
      "Epoch 24/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 140.1628\n",
      "Epoch 25/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 86.8088\n",
      "Epoch 26/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 56.2629\n",
      "Epoch 27/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 43.9149\n",
      "Epoch 28/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33.2925\n",
      "Epoch 29/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 28.7339\n",
      "Epoch 30/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 25.2571\n",
      "Epoch 31/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 23.9398\n",
      "Epoch 32/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 22.3688\n",
      "Epoch 33/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21.7179\n",
      "Epoch 34/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 22.2031\n",
      "Epoch 35/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21.5798\n",
      "Epoch 36/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21.1739\n",
      "Epoch 37/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21.3581\n",
      "Epoch 38/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.4755\n",
      "Epoch 39/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21.0666\n",
      "Epoch 40/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21.6684\n",
      "Epoch 41/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21.2292\n",
      "Epoch 42/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.6464\n",
      "Epoch 43/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.6325\n",
      "Epoch 44/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.7654\n",
      "Epoch 45/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.9563\n",
      "Epoch 46/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21.0983\n",
      "Epoch 47/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.1440\n",
      "Epoch 48/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21.3934\n",
      "Epoch 49/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.5005\n",
      "Epoch 50/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.8843\n",
      "Epoch 51/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.6043\n",
      "Epoch 52/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.8279\n",
      "Epoch 53/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21.3027\n",
      "Epoch 54/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.7361\n",
      "Epoch 55/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21.5555\n",
      "Epoch 56/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.2439\n",
      "Epoch 57/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21.0835\n",
      "Epoch 58/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21.3936\n",
      "Epoch 59/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.8747\n",
      "Epoch 60/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.2041\n",
      "Epoch 61/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.3529\n",
      "Epoch 62/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.9347\n",
      "Epoch 63/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21.4706\n",
      "Epoch 64/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.2953\n",
      "Epoch 65/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.6482\n",
      "Epoch 66/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.4458\n",
      "Epoch 67/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.4012\n",
      "Epoch 68/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.6610\n",
      "Epoch 69/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21.6419\n",
      "Epoch 70/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.9515\n",
      "Epoch 71/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21.9279\n",
      "Epoch 72/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21.5444\n",
      "Epoch 73/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.0923\n",
      "Epoch 74/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.2801\n",
      "Epoch 75/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.5629\n",
      "Epoch 76/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.8714\n",
      "Epoch 77/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21.1621\n",
      "Epoch 78/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21.3033\n",
      "Epoch 79/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.6173\n",
      "Epoch 80/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.5896\n",
      "Epoch 81/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.2163\n",
      "Epoch 82/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.8362\n",
      "Epoch 83/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21.5067\n",
      "Epoch 84/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.6627\n",
      "Epoch 85/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.1643\n",
      "Epoch 86/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21.1907\n",
      "Epoch 87/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.7830\n",
      "Epoch 88/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.5455\n",
      "Epoch 89/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 19.9848\n",
      "Epoch 90/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21.2630\n",
      "Epoch 91/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21.3534\n",
      "Epoch 92/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - loss: 20.5414\n",
      "Epoch 93/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.9488\n",
      "Epoch 94/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.7274\n",
      "Epoch 95/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.5886\n",
      "Epoch 96/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.6073\n",
      "Epoch 97/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.1859\n",
      "Epoch 98/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.4458\n",
      "Epoch 99/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 19.9222\n",
      "Epoch 100/100\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - loss: 20.8204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2425f81fe00>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(X_train,y_train,batch_size=32,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5d5af77e-98c8-485a-8d24-b7d538286329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step\n"
     ]
    }
   ],
   "source": [
    "ypred_train=ann.predict(X_train)\n",
    "ypred_test=ann.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fdb4da4b-9f0f-4b1b-bfec-5705bf5d5be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for train data: 20.702926104924323\n",
      "MSE for test data: 19.2048234895522\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"MSE for train data:\",mean_squared_error(y_train,ypred_train))\n",
    "print(\"MSE for test data:\",mean_squared_error(y_test,ypred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "43df8f83-7d60-42a6-8b38-fd979dbfbba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for train data  0.9288372575497132\n",
      "R2 for test data:  0.9343397531163401\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print(\"R2 for train data \",r2_score(y_train,ypred_train))\n",
    "print(\"R2 for test data: \",r2_score(y_test,ypred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8274764b-689a-43b0-90f0-d19d4121d187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
